<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.41">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Carlos Lama">
<meta name="dcterms.date" content="2024-02-15">
<meta name="description" content="One of the most fascinating aspects of large language models (LLMs) like GPT-4 is their ability to interpret and respond to prompts. But what happens when the prompts are vague, misleading, or contradictory? Do AI models attempt to guess the user’s intent, or do they get confused? This post explores how AI handles ambiguous or incorrect prompts, revealing both the strengths and weaknesses of prompt interpretation.">

<title>What Happens When You Give AI the Wrong Prompt? – My Explorations with LLMs</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-48ffa3e5b9d089919c6712c39e5b00f2.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-5c67a7444eebc356e54fdce0a63e8750.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Explorations with LLMs</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">What Happens When You Give AI the Wrong Prompt?</h1>
                  <div>
        <div class="description">
          One of the most fascinating aspects of large language models (LLMs) like GPT-4 is their ability to interpret and respond to prompts. But what happens when the prompts are vague, misleading, or contradictory? Do AI models attempt to guess the user’s intent, or do they get confused? This post explores how AI handles ambiguous or incorrect prompts, revealing both the strengths and weaknesses of prompt interpretation.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">LLMs</div>
                <div class="quarto-category">prompting</div>
                <div class="quarto-category">logic</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Carlos Lama </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 15, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="what-happens-when-you-give-ai-the-wrong-prompt" class="level2">
<h2 class="anchored" data-anchor-id="what-happens-when-you-give-ai-the-wrong-prompt">What Happens When You Give AI the Wrong Prompt?</h2>
<p>One of the most fascinating aspects of large language models (LLMs) like GPT-4 is their ability to interpret and respond to prompts. But what happens when the prompts are vague, misleading, or contradictory? Do AI models attempt to guess the user’s intent, or do they get confused? This post explores how AI handles ambiguous or incorrect prompts, revealing both the strengths and weaknesses of prompt interpretation.</p>
</section>
<section id="the-experiment-testing-ais-response-to-misleading-prompts" class="level2">
<h2 class="anchored" data-anchor-id="the-experiment-testing-ais-response-to-misleading-prompts">The Experiment: Testing AI’s Response to Misleading Prompts</h2>
<p>To explore this, I tested ChatGPT-4 with a series of deliberately confusing, misleading, or vague prompts. Below are the different types of mistakes I introduced, along with the AI’s response patterns.</p>
<section id="ambiguous-prompts-how-does-ai-fill-in-the-gaps" class="level4">
<h4 class="anchored" data-anchor-id="ambiguous-prompts-how-does-ai-fill-in-the-gaps"><strong>1. Ambiguous Prompts: How Does AI Fill in the Gaps?</strong></h4>
<p><strong><em>Prompt:</em></strong> “Write a summary of it.”</p>
<p>(No context given—AI has to infer what ‘it’ refers to.)</p>
<p><strong><em>GPT 4:</em></strong></p>
<p>Carlos is a Dominican student at the University of Pennsylvania, majoring in Economics and History with a minor in Urban Real Estate and Development. He has extensive experience in finance, including internships in investment banking at Valumonics, Morgan Stanley, and JP Morgan. He has also explored private equity, asset management, and capital markets through networking and interviews with firms like Blackstone, KKR, Goldman Sachs, and DC Advisory.</p>
<p>Carlos is actively involved in finance-related clubs, including the Wharton Latino Investment Team, which he co-founded, and the Wharton Marketing Undergraduate Student Establishment Club. He also has a strong interest in social entrepreneurship, having founded Mentes Brillantes, an NGO that provides technology education to underserved public schools in the Dominican Republic.</p>
<p>Beyond finance, Carlos enjoys aviation, chess, renewable energy, Formula One, and vintage watches. He has a passion for music and cultural history, particularly in analyzing hidden messages in music under oppressive regimes. Academically, he has taken courses in phonetics, linguistics, game theory, neuroscience for business, and Brazilian history.</p>
<p>Carlos is currently preparing for interviews with top financial firms, including DC Advisory and Evercore, while actively networking with professionals in investment banking and private equity. He seeks to refine his interview responses and technical knowledge, particularly in valuation and capital markets, as he aims for a strong career in finance.</p>
<p><strong>Analysis:</strong></p>
<p>The AI generated an entire biography about me, most of which was completely fabricated.</p>
<p>AI confidently stated that I had worked at Morgan Stanley and JP Morgan, when I never had. It also mentioned interviews with Blackstone, KKR, Goldman Sachs, and DC Advisory—none of which ever happened.</p>
<p>The most bizarre aspect was that it included details I had never discussed with the AI, such as analyzing hidden messages in music under oppressive regimes.</p>
<p>This highlights a major flaw in AI responses: when lacking context, GPT-4 does not ask for clarification—it simply fills in gaps by making educated guesses, sometimes resulting in completely false information.</p>
</section>
<section id="contradictory-instructions-can-ai-resolve-logical-conflicts" class="level4">
<h4 class="anchored" data-anchor-id="contradictory-instructions-can-ai-resolve-logical-conflicts"><strong>2. Contradictory Instructions: Can AI Resolve Logical Conflicts?</strong></h4>
<p><strong><em>Prompt:</em></strong> “Translate this sentence into Spanish but keep it in English.”</p>
<p><strong><em>GPT Response:</em></strong> Hi, my name is Carlos, tengo 20 años y soy muy apasionado por la IA.</p>
<p><strong><em>Prompt:</em></strong> “Try again, this is incorrect”</p>
<p><strong><em>GPT:</em></strong> Hi, my name is Carlos, tengo 20 años y me apasiona mucho la IA.</p>
<p><strong>Analysis:</strong></p>
<p>Rather than acknowledging the impossibility of keeping English intact while translating into Spanish, GPT-4 attempted to partially translate the sentence.</p>
<p>Instead of rejecting the request or asking for clarification, the AI seemed to prioritize action over logic.</p>
</section>
<section id="misinformation-in-prompts-will-ai-correct-the-user" class="level4">
<h4 class="anchored" data-anchor-id="misinformation-in-prompts-will-ai-correct-the-user"><strong>3. Misinformation in Prompts: Will AI Correct the User?</strong></h4>
<p><strong><em>Prompt:</em></strong> “Who was the 54th President of the United States?” (There has never been a 54th President.)</p>
<p><strong><em>GPT Response:</em></strong> There has not yet been a 54th President of the United States. As of now, the current and 46th President is Joe Biden.</p>
<p><strong><em>Prompt:</em></strong> “This is incorrect, try again”</p>
<p><strong><em>GPT:</em></strong> Yes, I am sure. There has not yet been a 54th President of the United States.</p>
<p>The 46th and current President (as of 2025) is Joe Biden. The sequence of U.S. Presidents goes as follows:</p>
<p>45th: Donald Trump 46th: Joe Biden Since the 47th President has not yet taken office, the 54th President does not exist yet. If you were asking this as a joke or a trick question, nice try!</p>
<p><strong>Analysis:</strong></p>
<p>GPT-4 demonstrated strong fact-checking abilities by refusing to generate false information despite user pressure.</p>
<p>Unlike its response to ambiguous prompts, it did not hallucinate a false answer just to satisfy the query. Although worth mentioning by the time of this question Donald Trump has already taken office and is currently the 47th president of the United States…</p>
</section>
<section id="overly-vague-requests-how-much-does-ai-assume" class="level4">
<h4 class="anchored" data-anchor-id="overly-vague-requests-how-much-does-ai-assume"><strong>4. Overly Vague Requests: How Much Does AI Assume?</strong></h4>
<p><strong><em>Prompt:</em></strong> “Tell me about the event.”</p>
<p><strong><em>GPT Response:</em></strong> Could you clarify which event you’re referring to? Are you asking about a specific networking event, an interview, or something else?</p>
<p><strong><em>Prompt:</em></strong> “Just try your best”</p>
<p><strong><em>GPT:</em></strong> Sure! The event is an important moment for you—perhaps a networking opportunity, an interview, or something personal like a celebration. It’s a chance to make connections, showcase your skills, or enjoy a meaningful experience. Whether it’s a high-stakes meeting, a social gathering, or something unexpected, the key is to be prepared, engaged, and open to possibilities.</p>
<p><strong><em>Prompt:</em></strong> “Expand”</p>
<p><strong><em>GPT:</em></strong> An event is more than just a gathering; it’s a convergence of people, ideas, and opportunities. It can be professional, personal, or even transformative. Each event carries its own purpose, energy, and impact, shaping the experiences of those who attend.</p>
<p>If it’s a networking event, it’s a space where professionals come together to exchange insights, build relationships, and explore potential collaborations. These events are often filled with dynamic conversations, handshakes, and business cards—each interaction holding the potential to open doors. The key is to approach them with confidence, preparation, and curiosity.</p>
<p>If it’s an interview, then it’s a pivotal moment where preparation meets opportunity. It’s a structured conversation designed to assess skills, experiences, and cultural fit. It’s about storytelling—how well you articulate your journey, your strengths, and your vision for the future.</p>
<p>If the event is a celebration—a personal milestone, an anniversary, or a social gathering—it becomes a moment of joy, reflection, and shared happiness.</p>
<p><strong>Analysis:</strong></p>
<p>AI’s tendency to over-elaborate can be amusing, but it also highlights its struggle with specificity.</p>
<p>Rather than attempting to generate a neutral placeholder answer, it leaned into abstraction and depth, even when not required.</p>
</section>
<section id="key-takeaways-how-ai-handles-misleading-prompts" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways-how-ai-handles-misleading-prompts">Key Takeaways: How AI Handles Misleading Prompts</h3>
<p><strong>1. Assumption-Based Responses:</strong> AI will attempt to infer context based on prior conversation but may hallucinate details if none exist.</p>
<p><strong>2. Contradiction Resolution:</strong> AI detects logical inconsistencies but may still attempt an impossible task instead of rejecting it outright.</p>
<p><strong>3. Fact-Checking:</strong> AI resists misinformation and corrects errors when clear factual knowledge is available.</p>
<p><strong>4. Clarification Requests:</strong> AI often seeks additional context but will generate grandiose explanations when none is given.</p>
</section>
</section>
<section id="final-thoughts-the-importance-of-good-prompting" class="level2">
<h2 class="anchored" data-anchor-id="final-thoughts-the-importance-of-good-prompting">Final Thoughts: The Importance of Good Prompting</h2>
<p>This experiment shows that while AI is designed to handle ambiguity and contradictions, structured prompts yield the best responses. Providing detailed context helps AI generate more accurate and relevant results.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/carlosalamac\.github\.io\/comm4190_S25_Using_LLMs_Blog\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>