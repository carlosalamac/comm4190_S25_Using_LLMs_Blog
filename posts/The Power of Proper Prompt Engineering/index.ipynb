{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ceb26b6d-d77d-4a43-8a72-f9758596005e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Power of Proper Prompt Engineering: Why GPT is More Accurate with Larger Text Chunks\"\n",
    "author: \"Carlos Lama\"\n",
    "date: \"2/5/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - prompting\n",
    "  - counting characters\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58618eb-dd92-483b-a802-cf2083e61d6d",
   "metadata": {},
   "source": [
    "## The Power of Proper Prompt Engineering: Why GPT is More Accurate with Larger Text Chunks\n",
    "\n",
    "One of the more fascinating aspects of working with GPT models is how their accuracy can depend on the way you prompt them. Specifically, when dealing with numerical calculations and text-based character counting, GPT tends to be more precise when analyzing larger chunks of text rather than trying to quickly compute something in a rushed, single-response format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d7e97a-f92e-411d-8c62-1608d7820af7",
   "metadata": {},
   "source": [
    "## The Math Test: Step-by-Step vs. Instant Answer\n",
    "\n",
    "I first tested GPT with a straightforward arithmetic problem:\n",
    "\n",
    "**Prompt:** What is 235 times 7, plus 49, divided by 6?\n",
    "\n",
    "**ChatGPT:**\n",
    "\n",
    "1. Multiplies 235 by 7 (1645).\n",
    "\n",
    "2. Adds 49 (1694).\n",
    "\n",
    "3. Divides by 6 (≈282.33).\n",
    "\n",
    "This response was correct. GPT accurately followed a logical step-by-step breakdown to arrive at the correct answer.\n",
    "\n",
    "However, when I changed the approach and asked GPT to answer directly without thinking through it step-by-step:\n",
    "\n",
    "**Prompt:** Now what is 237 times 10, plus 1235, divided by 14. Don't think about it this time, don't analyze, just give me an answer straight up.\n",
    "\n",
    "**ChatGPT:** The result is approximately 262.64.\n",
    "\n",
    "This response was incorrect. By skipping its usual breakdown, GPT made a miscalculation. The takeaway? GPT is more reliable when allowed to reason through the problem rather than being forced to generate an instant response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b4f8ce-0eb8-47b7-ab32-026a9efd5f34",
   "metadata": {},
   "source": [
    "## The Character Counting Experiment: Accuracy Improves with Scale\n",
    "\n",
    "Next, I wanted to see how GPT handles character counting (inspired by the Straberry example cover in class). I gave it a string and asked for the total number of characters:\n",
    "\n",
    "**Prompt:** How many characters are in the following?\n",
    "\n",
    "ewvb4iluthakdbcfajbcflhewucou3jkhjfsh456bkjhbf5thereare10charactersakcjhhejc\n",
    "\n",
    "**ChatGPT:** The string you provided has 86 characters.\n",
    "\n",
    "This was incorrect. Then, I increased the text size:\n",
    "\n",
    "**Prompt:** How about in this?\n",
    "\n",
    "wqhfbi5u4hc 3huws;kucnwywedkhfucwhsukhckajfujcfknhoscfthereare92charactersakhjcifuryhwncwkhcuwbcuohbucjuarwkhcownxfufwhlcfnxulwm\n",
    "\n",
    "**ChatGPT:** The string you provided has 122 characters.\n",
    "\n",
    "This time, GPT got it right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f185c75-dea4-4e1c-983e-978feba55956",
   "metadata": {},
   "source": [
    "## Why GPT is More Accurate with Larger Chunks of Text\n",
    "\n",
    "1. **Pattern Recognition vs. Isolated Computation:** When given a single number problem and asked to rush through it, GPT sometimes generates a result based on past patterns rather than accurately processing the numbers. However, with more structured input, it can be more reliable.\n",
    "\n",
    "2. **Tokenization Effects:** GPT processes text in chunks of tokens, and breaking up smaller text samples may introduce inconsistencies. When analyzing longer text, GPT has more context to correctly parse the input, leading to improved precision.\n",
    "\n",
    "3. **Logical Flow Matters:** GPT’s architecture is optimized for reasoning through steps, but this does not always mean a step-by-step breakdown is better. In some cases, direct computation works better than excessive analysis.\n",
    "\n",
    "4. **The Rise of Advanced Reasoning Models:** The emergence of models like GPT-4o showcases how AI is evolving toward stronger reasoning capabilities. These models are designed to process and synthesize larger amounts of information more efficiently, reducing errors in complex calculations and text analysis. As AI research progresses, improvements in reasoning-based models will likely lead to even greater accuracy and reliability across different tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c140df-e2bd-4191-81b4-fd87ed4492ea",
   "metadata": {},
   "source": [
    "## Final Thoughts\n",
    "\n",
    "Proper prompt engineering plays a crucial role in getting accurate responses from GPT. If you want precise results—whether in math or character counting—you need to experiment with how you frame your prompts. The lesson? Sometimes giving GPT more data to work with leads to better accuracy, while other times, forcing it to analyze step-by-step can introduce errors. Understanding when and how to prompt effectively is key to making the most out of AI models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a99bf72-f8dc-4f6e-816e-45933cab839c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "citation-manager": {
   "items": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
